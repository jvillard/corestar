In a moment of insanity, I, Radu Grigore, decided to throw away lots of
perfectly functioning code, and replace it with some other lot of perfectly
functioning code.  Since the beginning, coreStar had dealt with equalities,
disequalities, uninterpreted functions, and related matters by its own.
Specifically, it had three modules (Congruence, Cterm, Clogic), the first of
which was very complicated, and the other twos heaping on top of it.  For
efficiency, it represented formulas in a very complicated way, which made it
difficult to perform operations such as ‘build P*Q out of P and Q’.  We (Rasmus
and I) tried to remedy the situation by implementing the said operations.  In
the process, we fixed several glaring bugs in the old code, and replaced them
with subtle bugs, which we were subsequently unable to repair.

Needless to say, I consider this state of affairs as unsatisfactory.

So, here is the plan, in brief format:  Discharge anything that has to do with
equalities and uninterpreted functions to an SMT solver, and keep the formula
representation inside coreStar as simple as possible.  Don't worry about
efficiency; fix it later if necessary.

Now, a bit more detail.  The main data type that we must define is that for
expressions.  I plan to use these to represent several things:
  - terms: 0, 1, x, 1 + x, ...
  - formulas: x == y,  x.f |-> y,  x == y * y != z
  - patterns:  _x.next |-> _y * _y.next |-> _x
These share several common operations:
  - construction:  the operators used in patterns are the same as those used in
    formulas and terms, although operators used in formulas are disjoint from
    those used in terms
  - convert to normal forms, such as the form expected by the prover; a normal
    form could be subtype, but I'd prefer just semantic checks (e.g.
    is_normal_form_foo : formula -> bool)
Roughly, we would need to distinguish several types of operators, such as
  - those used in terms: +, -, ...
  - equality and disequality (they are special because pattern matching is done
    modulo equality; see later)
It is, however, not completely clear to me how many categories we should have.
For example, are spatial predicates treated mostly the same or mostly different
from non-spatial (pure) predicates?  In the former case, you'd not want a
distinction at the type level; in the latter case, you would.

*Remark:*  The previous paragraph raises the question of how much information to
encode in types.  My personal preference appears below.  I'm unsure whether what
I propose is too little or too much.  I suspect most people (that means you)
would think ‘too little’.  It seems to me there is no such thing as the ‘right
amount’, but there is a reasonable range, and the most important thing is to not
go overboard.  One reason why I tilt towards the ‘too little’ end of the range
is that I'm uncertain what are the right categories of operators, and code that
uses types less feels more malleable.

There are also operations that apply only to some particular kinds of
expressions, such as:
  - terms and formulas: conversion to the SMT format (I think there's no such
    thing as a pattern in SMT)
  - terms/formulas vs pattern: matching

*TODO:* Since we don't want to handle equalities and since pattern matching is
done modulo equalities, we must use Z3 during pattern matching.  We need to
clarify how this is done.


--------------------------------------------------------------------------------
- Formula representation

The two main constructors are
  make_app : operator → formula list → formula
  make_var : string → formula
and the accompanying deconstructors are
  break_app : formula → (operator * formula list)
  break_var : formula → srting

*Why:*  Of course, this could be just a (transparent) variant type.  Why go
through the trouble to hide it behind constructors/deconstructors?  I think it's
likely that we would have to implement hash-consing [1], such that we can
determine in O(1) time whether two formulas/terms are syntactically equal.  The
old implementation was doing this by using some integer identifiers in
Congruence, which had a limited scope, meaning that it was *sometimes* possible
to compare terms quickly.

Structural equality should be tested using the function
  eq : formula → formula → bool
rather than the OCaml's polymorphic comparison =.  This way, it will be easier
to switch to a new implementation in the future.

*TODO:* I'm not sure whether [operator] should be just a string, or a variant
that identifies the operators 

Some other helpers need to be provided.  For example, instead of
  make_app Star [a; b]
it's more convenient to say
  make_star a b
But, such conveniences should be easy to implement in terms of the above.

*Why:*  Destructors are supposed to make it reasonably convenient to use pattern
matching, even if the variant type used for formulas is not transparent.


--------------------------------------------------------------------------------
- Sequent representation

The coreStar sequents have the shape
  R | P ⊢ Q
and the semantics
  if h ⊨ P * R, then h ⊨ Q * R
for some definition of ⊨.

*TODO:* I say ‘some’ because I'm not sure whether we assume the intuitionistic
definition in some essential way.  (In the past I simply assumed the
intuitionistic definition when thinking about it, but other users, such as
Jules, probably aren't.  Another way to put it: While modifying the alt-abd
branch I didn't pay attention to whether those modifications would make life
hard for Jules. Sorry.)

I *think* it might be fine to have a transparent type
  type sequent =
    { sequent_frame : formula
    ; sequent_hypothesis : formula
    ; sequent_consequence : formula }




[1] http://youtu.be/IK0G04Mry3s


vim:spell:tw=80:fo+=t:
